{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Library\n",
    "import tensorflow.keras\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import regularizers, optimizers\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read TrainTest Data\n",
    "# path = '../input/super-ai-engineer-2021-thai-food-labeling/'\n",
    "path_traincsv = path+'new_train.csv'\n",
    "path_valcsv = path+'new_val.csv'\n",
    "path_testcsv = path+'new_submission.csv'\n",
    "df_train=pd.read_csv(path_traincsv)\n",
    "df_valid=pd.read_csv(path_valcsv)\n",
    "df_test=pd.read_csv(path_testcsv)\n",
    "df_train=df_train\n",
    "df_valid=df_valid\n",
    "df_train['labels']=df_train['labels'].apply(lambda x: x.split(' '))\n",
    "df_valid['labels']=df_valid['labels'].apply(lambda x: x.split(' '))\n",
    "dftotal = pd.concat([df_train,df_valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dftotal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "image_path = ##Your image_path\n",
    "entrys=[]\n",
    "result=[]\n",
    "all_files=[]\n",
    "import glob\n",
    "for root, directories, files in os.walk(image_path):\n",
    "    for directory in directories:\n",
    "        all_files.append(directory) ##ได้labels\n",
    "        ###############หาpathรูป#########\n",
    "        entry_path = os.path.join(image_path, directory)\n",
    "        for entry in glob.glob(entry_path + '/*[0-9].*'):\n",
    "            entry_path = os.path.join(image_path, entry)\n",
    "            # print(entry)\n",
    "            entrys.append(entry)\n",
    "            result.append((entry, directory))\n",
    "            # for files in glob.glob(image_path + '/*[0-9].*'):\n",
    "            #     print(files)\n",
    "            \n",
    "columns = [\"filename\", \"labels\"]\n",
    "df = pd.DataFrame.from_records(result, columns=columns)   \n",
    "df['labels']=df['labels'].apply(lambda x: x.split(','))\n",
    "df.tail(5)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defined your label\n",
    "classes = ['0','1','10','100','101','102','103','104','105','106','107','108','109','11','110','111','112','113','114','115','116','117','118','119','12','120','121','122','123','124','125','126','127','128','129','13','130','131','132','133','134','135','136','137','138','139','14','140','141','142','143','144', '145','146','147', '148','149','15','150','151','152','153','154', '155','156','157','158','159','16', '160','161','162','163','164','165','166','167','168','169','17','170','171','172','173','174','175','176','177','178','179','18','180','181','182','183','184','185','186','187','188','189','19','190','191','192','193','194','195','196','197','198','199','2','20','200','201','202','203','204','205', '206','207','208','209','21','210','211','212','213', '214','215','216','217','218','219','22','220','221','222','223', '224','225','226','227','228', '229','23','230','231','232','233','234','235','236','237','238','239','24','240','241','242','243','244','245','246','247','248','249','25','250','251','252','253','254','255','256','257','258','259','26','260','261','262','263','264', '265','266','267','268','269','27','270','271','272','273','274','275','276','277','278','279','28','280','281','282','283','284','285','286','287','288','289', '29','290','291','292','293','294','295','296','297','298','299','3','30','300','301','31','32','34','35','36','37','38','39','4','40','41','42','43','44','45','46','47','48','49','5','50','51','52','53','54','55','56','57','58','59','6','60','61','62','63','64','65','66','67','68','69','7','70','71','72','73','74','75','76','77','78','79','8','80','81','82','83','84','85','86','87','88','89','9','90','91','92','93','94','95','96','97', '98','99']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen=ImageDataGenerator(rescale=1./255.\n",
    "                            featurewise_center=True,\n",
    "                            featurewise_std_normalization=True,\n",
    "                            rotation_range=20,\n",
    "                            width_shift_range=0.2,\n",
    "                            height_shift_range=0.2,\n",
    "                            horizontal_flip=True)\n",
    "\n",
    "train_generator=datagen.flow_from_dataframe(\n",
    "dataframe=dftotal,\n",
    "directory=\"./hackathon/\",\n",
    "x_col=\"filename\",\n",
    "y_col=\"labels\",\n",
    "subset=\"training\",\n",
    "batch_size=256,\n",
    "seed=42,classes=classes,\n",
    "shuffle=True,\n",
    "class_mode=\"categorical\",\n",
    "target_size=(299,299))\n",
    "\n",
    "valid_generator=datagen.flow_from_dataframe(\n",
    "dataframe=df[0:3000],\n",
    "directory=\"./\",\n",
    "# dataframe=df_valid,\n",
    "# directory=\"./hackathon/\",\n",
    "x_col=\"filename\",\n",
    "y_col=\"labels\",\n",
    "subset=\"training\",\n",
    "batch_size=256,\n",
    "seed=42,classes=classes,\n",
    "shuffle=True,\n",
    "class_mode=\"categorical\",\n",
    "target_size=(299,299))\n",
    "\n",
    "test_datagen=ImageDataGenerator(rescale=1./255.)\n",
    "\n",
    "test_generator=test_datagen.flow_from_dataframe(\n",
    "dataframe=df_test,\n",
    "directory=\"./hackathon/\",\n",
    "x_col=\"filename\",\n",
    "y_col=None,\n",
    "batch_size=256,\n",
    "seed=42,\n",
    "shuffle=False,\n",
    "class_mode=None,\n",
    "target_size=(299,299))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Create Model\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, Flatten, GlobalAveragePooling2D\n",
    "from tensorflow.keras import layers\n",
    "base_model= tf.keras.applications.InceptionV3(include_top=False,weights=\"imagenet\")\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "x = base_model.output\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Dropout(0.2)(x)\n",
    "prediction = layers.Dense(301, activation='sigmoid',dtype=tf.float32)(x)   \n",
    "model = tf.keras.Model(inputs=base_model.input, outputs=prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath='./my_best_model.hdf5'\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=filepath, monitor='val_loss')\n",
    "callbacks = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, verbose=1,min_delta=0.001)\n",
    "\n",
    "model.compile(optimizer =tf.keras.optimizers.Adam(learning_rate=1e-2), loss = 'binary_crossentropy',metrics = ['acc'])\n",
    "batch_size = 64\n",
    "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\n",
    "model.fit_generator(generator=train_generator,\n",
    "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps=STEP_SIZE_VALID,callbacks=[callbacks,checkpoint],\n",
    "                    epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Predict and submission on kaggle ##\n",
    "proba = model.predict(test_generator)\n",
    "submission=[]\n",
    "for i,p in enumerate(proba):\n",
    "  index_p=np.where(proba[i] >0.1)\n",
    "  class_pred=[]\n",
    "  for j in index_p[0]:\n",
    "    k = int(classes[int(j)])\n",
    "    # print(j, labels['label'].iloc[j])\n",
    "    class_pred.append(k)\n",
    "    submission.append(sorted(class_pred))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
